{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Análisis de Opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Importaciones necesarias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el desarrollo del problema, se importan librerías y módulos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Descripción de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dispone de dos dataframes, uno de entrenamiento y otro de prueba. Cada uno de ellos posee 3554 registros. A su vez, cada registro es descrito por dos características: *sentimiento*, cuyo valor puede ser +1 (opinión positiva) ó -1 (opinión negativa) y *texto*, que contiene la opinión del espectador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Se leen archivos de entrada que contiene datos de entrenamiento\n",
    "ftr = open(\"polarity.train\", \"r\")\n",
    "#Se leen archivos de entrada que contiene datos de prueba\n",
    "fts = open(\"polarity.dev\", \"r\")\n",
    "\n",
    "#Se crea dataframe para datos de entrenamiento\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "train_df['Sentiment'] = train_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    "\n",
    "#Se crea dataframe para datos de prueba\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "test_df['Sentiment'] = test_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    " \n",
    "#Cantidad de registros por cada set de datos\n",
    "num_train = train_df.shape[0]\n",
    "num_test = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Preprocesamiento de texto: Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor* para obtener tokens de un texto (con y sin stemming). Notar que la función recibe como parámetros el texto a analizar, junto con la opción (*True*) o no (*False*) de realizar stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor(text, stemming):\n",
    "    #Se utiliza algoritmo de Porter para stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "\n",
    "    if stemming:\n",
    "        #Se realiza lower-casing y stemming\n",
    "        wordtokens = [stemmer.stem(word.lower()) \\\n",
    "                 for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    else:\n",
    "        #Se realiza lower-casing, pero no stemming\n",
    "        wordtokens = [word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "\n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words += \" \" + word\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se listan los resultados obtenidos utilizando la función *word_extractor* sobre las frases de ejemplo entregadas en el enunciado. Primero se trabaja con stemming, haciendo uso del algoritmo de Porter:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eat cake  \n",
    "**I loved eating the cake**: love eat cake  \n",
    "**I do not love eating cake**: love eat cake  \n",
    "**I don’t love eating the cake**: n’t love eat cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simpl , whi n’t done alreadi  \n",
    "**If you’re good at something, never do it for free**: ’re good someth , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se obtienen resultados pobres. Ello se manifiesta principalmente en que para las cuatro primeras expresiones, el resultado final es el mismo, aún cuando algunas de ellas tienen significados opuestos entre sí. Además, muchas de las expresiones generadas contienen tokens que no tiene significado alguno y se reducen tokens que no son verbos, como *something* y *already*.\n",
    "\n",
    "Sin el uso de stemming, los resultados son los siguientes:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: love eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se observa que los verbos no son reducidos a su tronco léxico base, pero ello favorece que no se reduzcan tokens que no corresponde reducir, valga la redundancia. Sin embargo, sigue siendo imposible distinguir entre una frase determinada y su negación. De todas maneras, se aprecia una mayor coherencia en las expresiones resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Preprocesamiento de texto: Lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor2* para obtener tokens de un texto por medio del proceso de lematización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor2(text, sw):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "    #Se realiza lower-casing y lematizacion\n",
    "    wordtokens = [wordlemmatizer.lemmatize(word.lower()) \\\n",
    "             for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    \n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords, en caso de que sw == True\n",
    "    if sw == True:\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words += \" \" + word\n",
    "    else:\n",
    "        for word in wordtokens:\n",
    "            words += \" \" + word\t\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando las mismas expresiones de la secci ́on anterior, se obtienen los siguientes resultados:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: loved eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Los resultados son practicamente idénticos a los obtenidos sin realizar stemming, excepto por la tercera expresión, donde la forma verbal *loved* se mantiene, pero no marca una diferencia significativa.\n",
    "\n",
    "En resumen, se puede ver que, aunque tanto stemming como lematización tienen sus ventajas y desventajas, lematización obtiene mejores resultados, o en su defecto, la no utilización de stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Construcción de vocabulario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a generar una representación vectorial para cada una de las instancias de la variable *texto* presentes tanto en el dataset de entrenamiento como en el de prueba. Para ello, se utiliza la función *word_extractor2*, junto con la opción de filtrar stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se genera representación vectorial de la variable texto para datos de entrenamiento\n",
    "texts_train1 = [word_extractor2(text, True) for text in train_df.Text]\n",
    "#Se genera representación vectorial de la variable texto para datos de prueba\n",
    "texts_test1 = [word_extractor2(text, True) for text in test_df.Text]\n",
    "\n",
    "vectorizer1 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer1.fit(np.asarray(texts_train1))\n",
    "features_train1 = vectorizer1.transform(texts_train1)\n",
    "features_test1 = vectorizer1.transform(texts_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estas representaciones vectoriales, se obtiene el vocabulario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \n",
      "vocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \n",
      "frecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \n",
      "acompañado de su correspondiente frecuencia:\n",
      "\n",
      "film : 583 ocurrencias\n",
      "movie : 503 ocurrencias\n",
      "one : 259 ocurrencias\n",
      "like : 255 ocurrencias\n",
      "ha : 235 ocurrencias\n",
      "make : 186 ocurrencias\n",
      "story : 177 ocurrencias\n",
      "character : 165 ocurrencias\n",
      "good : 154 ocurrencias\n",
      "time : 148 ocurrencias\n"
     ]
    }
   ],
   "source": [
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocabulario = vectorizer1.get_feature_names()\n",
    "dist = list(np.array(features_train1.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "#Se determina la frecuencia de cada token en el vocabulario\n",
    "word_freq = zip(vocabulario, dist)\n",
    "#Se ordenan los tokens por su frecuencia en orden descendente\n",
    "word_freq_ordered = reversed(sorted(word_freq, key=lambda tup: tup[1]))\n",
    "positions = 10\n",
    "\n",
    "#Se imprime top 10 de tokens (esto es, los 10 tokens mas frecuentes en el vocabulario)\n",
    "print ('Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \\nvocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \\nfrecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \\nacompañado de su correspondiente frecuencia:\\n')\n",
    "for tag, count in word_freq_ordered:\n",
    "    if (positions > 0):\n",
    "        print tag,':', count, 'ocurrencias'\n",
    "        positions -= 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Desempeño de clasificadores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ésta sección, se muestra el desempeño de diversos modelos de clasificación aplicados sobre los datos provistos. Para esto, se expondrá un reporte por cada modelo. Dicho reporte indica la precisión, el recall, el valor-F (también conocido como F1-score) y el soporte de cada clase. El reporte es generado por la función *score_model*, que se implementa a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se construye funcion score_model, la cual evalua el desempeno de un determinado clasificador\n",
    "def score_model(model, x, y, xt, yt, text):\n",
    "    acc_train = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1], yt[:-1])\n",
    "    print 'Precisión datos de entrenamiento %s: %f'%(text, acc_train)\n",
    "    print 'Precisión datos de prueba %s: %f'%(text, acc_test)\n",
    "    print 'Análisis detallado de resultados sobre set de prueba:'\n",
    "    print (classification_report(yt, model.predict(xt), target_names = ['clase +1', 'clase -1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1 Clasificador Bayesiano Ingenuo Binario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, se implementa la función *NAIVE_BAYES*, que servirá para el entrenamiento/ajuste de un clasificador Bayesiano Binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion clasificador bayesiano ingenuo binario\n",
    "def NAIVE_BAYES(x, y, xt, yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_model(model, x, y, xt, yt, 'BernoulliNB')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, se emplea dicha función para construir un clasificador aplicado a los siguientes casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.958638\n",
      "Precisión datos de prueba BernoulliNB: 0.738531\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.73      0.74      1803\n",
      "   clase -1       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 1: filtrando stopwords, con lematizacion\n",
    "model1 = NAIVE_BAYES(features_train1, labels_train, features_test1, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se requiere generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train2 = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test2 = [word_extractor2(text, False) for text in test_df.Text]\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer2.fit(np.asarray(texts_train2))\n",
    "features_train2 = vectorizer2.transform(texts_train2)\n",
    "features_test2 = vectorizer2.transform(texts_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.955262\n",
      "Precisión datos de prueba BernoulliNB: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 2: sin filtrar stopwords, con lematizacion\n",
    "model2 = NAIVE_BAYES(features_train2, labels_train, features_test2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que al usar lematización, se obtiene una mayor precisión sobre el set de entrenamiento si se filtran stopwords, pero la precisión es mayor sobre el set de prueba en el caso en que no se filtran. De todas maneras, las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en la sección anterior, es necesario generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train3 = [word_extractor(text, True) for text in train_df.Text]\n",
    "texts_test3 = [word_extractor(text, True) for text in test_df.Text]\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer3.fit(np.asarray(texts_train3))\n",
    "features_train3 = vectorizer3.transform(texts_train3)\n",
    "features_test3 = vectorizer3.transform(texts_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.942881\n",
      "Precisión datos de prueba BernoulliNB: 0.747819\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = NAIVE_BAYES(features_train3, labels_train, features_test3, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se obtiene una mayor precisión sobre el set de entrenamiento al usar lematización, pero la precisión sobre el set de prueba es mayor con stemming, aunque sólo al comparar con el caso en que se filtran stopwords. Si se toman en cuenta la precisión y recall por cada clase (en cada caso), puede decirse que los mejores resultados se consiguen al usar lematización y no filtrar stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han tomado cinco textos y se muestra la predicción sobre cada uno. Sólo se considera el caso 1, dado a que es el modelo que obtiene los mejores resultados (NOTA: Dado a que el siguiente código escoge los textos en forma azarosa, los resultados que imprime no coincidirán con los ejemplos analizados más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13653869  0.86346131] an effectively creepy , fear-inducing ( not fear-reducing ) film from japanese director hideo nakata , who takes the superstitious curse on chain letters and actually applies it .\n",
      "\n",
      "[ 0.4025737  0.5974263] a treat for its depiction on not giving up on dreams when you're a struggling nobody .\n",
      "\n",
      "[ 0.18361022  0.81638978] it certainly won't win any awards in the plot department but it sets out with no pretensions and delivers big time .\n",
      "\n",
      "[ 0.07491648  0.92508352] . . . a guiltless film for nice evening out .\n",
      "\n",
      "[ 0.055437  0.944563] this bracingly truthful antidote to hollywood teenage movies that slather clearasil over the blemishes of youth captures the combustible mixture of a chafing inner loneliness and desperate grandiosity that tend to characterize puberty .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: ’a’ for creativity but comes across more as a sketch for a full-length comedy .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "La opinión es mixta, pero el clasificador la considera más cercana a una opinión negativa.\n",
    "\n",
    "**Texto**: every once in a while , a movie will come along that turns me into that annoying specimen of humanity that i usually dread encountering the most - the fanboy  \n",
    "**Predicción -1**: 0,94  \n",
    "**Predicción +1**: 0,06\n",
    "\n",
    "La opinión es algo ambigua. Sin embargo, el clasificador la considera más bien una opinión negativa.\n",
    "\n",
    "**Texto**: it just goes to show , an intelligent person isn’t necessarily an admirable storyteller .  \n",
    "**Predicción -1**: 0,53  \n",
    "**Predicción +1**: 0,47\n",
    "\n",
    "Se ve que la opinión es negativa, pero el clasificador la considera más cercana a una opinión mixta.\n",
    "\n",
    "**Texto**: the movie is for fans who can’t stop loving anime , and the fanatical excess built into it .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "Es una opinión más bien neutra, pero el clasificador la asocia más como una crítica negativa.\n",
    "\n",
    "**Texto**: there is truth here  \n",
    "**Predicción -1**: 0,44  \n",
    "**Predicción +1**: 0,56\n",
    "\n",
    "Es una opinión cuyo juicio de valor es difícil de determinar, por lo que resulta apropiado que la predicción del clasificador sea mixta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.5.2 Clasificador Bayesiano Ingenuo Multinomial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la función *MULTINOMIAL*, que se utilizará para el entrenamiento/ajuste de un clasificador Bayesiano Ingenuo Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion clasificador bayesiano ingenuo multinomial\n",
    "def MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x,y)\n",
    "    score_model(model, x, y, xt, yt, \"MULTINOMIAL\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de ésta función, se estudian los mismos casos de la sección anterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.959764\n",
      "Precisión datos de prueba MULTINOMIAL: 0.739375\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.73      0.74      1803\n",
      "   clase -1       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 1: filtrando stopwords, con lematizacion\n",
    "model1 = MULTINOMIAL(features_train1, labels_train, features_test1, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.955824\n",
      "Precisión datos de prueba MULTINOMIAL: 0.752322\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.75      0.75      1803\n",
      "   clase -1       0.75      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 2: sin filtrar stopwords, con lematizacion\n",
    "model2 = MULTINOMIAL(features_train2, labels_train, features_test2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, al usar lematización, se obtiene una mayor precisión sobre el set de entrenamiento si se filtran stopwords, pero la precisión es mayor sobre el set de prueba en el caso en que no se filtran. De todas maneras, las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.942600\n",
      "Precisión datos de prueba MULTINOMIAL: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.75      0.75      1803\n",
      "   clase -1       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = MULTINOMIAL(features_train3, labels_train, features_test3, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se obtiene una mayor precisión sobre el set de entrenamiento al usar lematización, pero la precisión sobre el set de prueba es mayor con stemming, aunque sólo en comparación con el caso en que se filtran stopwords. Si se toman en cuenta la precisión y recall por cada clase (en cada caso), puede decirse que los mejores resultados se consiguen al usar lematización y no filtrar stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la misma lógica que en la sección 2.5.1.4. Se considera sólo el primer caso, para el que se obtienen los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95943091  0.04056909] the slapstick is labored , and the bigger setpieces flat .\n",
      "\n",
      "[ 0.00136853  0.99863147] an honest , sensitive story from a vietnamese point of view .\n",
      "\n",
      "[ 0.73020134  0.26979866] despite its raucous intent , xxx is as conventional as a nike ad and as rebellious as spring break .\n",
      "\n",
      "[  9.99968080e-01   3.19203313e-05] when a film is created solely because it's a marketable product , soulless and ugly movies like this are the result . let your silly childhood nostalgia slumber unmolested .\n",
      "\n",
      "[ 0.57944211  0.42055789] the story feels more like a serious read , filled with heavy doses of always enticing sayles dialogue .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se analizan los siguientes ejemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: passionate , irrational , long-suffering but cruel as a tarantula , helga figures prominently in this movie , and helps keep the proceedings as funny for grown-ups as for rugrats  \n",
    "**Predicción -1**: 0,04  \n",
    "**Predicción +1**: 0,96\n",
    "\n",
    "La opinión es positiva, y así es como le predice el clasificador.\n",
    "\n",
    "**Texto**: an eccentric little comic/thriller deeply in love with its own quirky personality .  \n",
    "**Predicción -1**: 0,23  \n",
    "**Predicción +1**: 0,77\n",
    "\n",
    "La opinión puede considerarse como negativa, pero el clasificador la considera más cercana a una\n",
    "opinión positiva.\n",
    "\n",
    "**Texto**: rice never clearly defines his characters or gives us a reason to care about them .  \n",
    "**Predicción -1**: 0,94  \n",
    "**Predicción +1**: 0,06\n",
    "\n",
    "La opinión es negativa, y así es como el clasificador lo predice.\n",
    "\n",
    "**Texto**: after a while , the only way for a reasonably intelligent person to get through the country bears is to ponder how a whole segment of pop-music history has been allowed to get wet , fuzzy and sticky .  \n",
    "**Predicción -1**: 0,98  \n",
    "**Predicción +1**: 0,02\n",
    "\n",
    "La opinión es negativa, y así es como lo predice el clasificador.\n",
    "\n",
    "**Texto**: The music and the stars aren’t enough to save the movie .  \n",
    "**Predicción -1**: 0,97  \n",
    "**Predicción +1**: 0,03\n",
    "\n",
    "La opinión es negativa, y así es como el clasificador lo entiende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3 Modelo de regresión logística regularizado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la función *LOGIT*, con el propósito de entrenar/ajustar modelos de Regresión Logística Regularizados mediante la norma *l2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion modelo de regresion logistica regularizado\n",
    "def LOGIT(x,y,xt,yt, bestvalue):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01, 0.1, 10, 100, 1000]\n",
    "    if bestvalue == 0:\n",
    "        for C in Cs:\n",
    "            print \"Usando C= %f\"%C\n",
    "            model = LogisticRegression(penalty='l2', C=C)\n",
    "            model= model.fit(x,y)\n",
    "            score_model(model, x, y, xt, yt, \"LOGISTIC\")\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=bestvalue)\n",
    "        model = model.fit(x,y)\n",
    "        score_model(model,x,y,xt,yt, \"LOGISTIC\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que el efecto esperado del parámetro C es regularizar el modelo, es decir, encontrar valores para los coeficientes asociados a cada variable presente en la regresión, de tal manera que se minimice el error de predicción. Así, se estudian los mismos tres casos de siempre, buscando también verificar, en cada uno de ellos, cual es el parámetro C más adecuado para regularizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.787563\n",
      "Precisión datos de prueba LOGISTIC: 0.679144\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.67      0.72      0.69      1803\n",
      "   clase -1       0.69      0.64      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.891390\n",
      "Precisión datos de prueba LOGISTIC: 0.718829\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.72      0.72      0.72      1803\n",
      "   clase -1       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.719674\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.714044\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.70      0.71      1803\n",
      "   clase -1       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.715170\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOGIT(features_train1, labels_train, features_test1, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las métricas que se exponen previamente, se elige el parámetro C = 10 como el más apropiado para realizar la regresión, dado que presenta un buen equilibrio entre precisión sobre el set de entrenamiento y precisión sobre el set de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.721159\n",
      "Precisión datos de prueba LOGISTIC: 0.672390\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.67      0.69      0.68      1803\n",
      "   clase -1       0.67      0.66      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.884074\n",
      "Precisión datos de prueba LOGISTIC: 0.717140\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.72      0.71      0.72      1803\n",
      "   clase -1       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.725865\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.70      0.72      1803\n",
      "   clase -1       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.721925\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.69      0.72      1803\n",
      "   clase -1       0.70      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.720518\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.69      0.72      1803\n",
      "   clase -1       0.70      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = LOGIT(features_train2, labels_train, features_test2, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo las mismas razones de la sección anterior, se aprecia que nuevamente es apropiado eligir C = 10 como parámetro de regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.781373\n",
      "Precisión datos de prueba LOGISTIC: 0.691528\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.69      0.72      0.70      1803\n",
      "   clase -1       0.70      0.66      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.882386\n",
      "Precisión datos de prueba LOGISTIC: 0.728961\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.74      0.73      1803\n",
      "   clase -1       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.999719\n",
      "Precisión datos de prueba LOGISTIC: 0.724740\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.72      0.73      1803\n",
      "   clase -1       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.717703\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.712637\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.70      0.71      1803\n",
      "   clase -1       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = LOGIT(features_train3, labels_train, features_test3, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los mismos motivos expuestos en las dos secciones previas, es conveniente regularizar con C = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar en forma conjunta los tres casos involucrados, se observa que la precisión sobre el set de entrenamiento es la misma, independiente de que se filtren o no stopwords. Sin embargo, la precisión sobre el set de prueba es mayor en el segundo caso. Además, la precisión sobre ambos sets de datos es siempre superior al usar lematización, respecto a usar stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se toman cinco textos aleatoreamente y se muestra la predicción sobre cada uno. Nuevamente, se considera el caso 1, junto con C = 10, pues es la combinación que entrega los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54086223  0.45913777] [gai] comes closer to any actress i can remember to personifying independence in its purest and , yes , most intimidating form .\n",
      "\n",
      "[ 0.86082351  0.13917649] the problem is that the movie has no idea of it is serious or not .\n",
      "\n",
      "[ 0.97468937  0.02531063] sadly , though many of the actors throw off a spark or two when they first appear , they can't generate enough heat in this cold vacuum of a comedy to start a reaction .\n",
      "\n",
      "[ 0.83633611  0.16366389] ritchie's film is easier to swallow than wertmuller's polemical allegory , but it's self-defeatingly decorous .\n",
      "\n",
      "[ 0.2314223  0.7685777] a clash between the artificial structure of the story and the more contemporary , naturalistic tone of the film . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: entertains by providing good , lively company .  \n",
    "**Predicción -1**: 0,01  \n",
    "**Predicción +1**: 0,99\n",
    "\n",
    "La opinión es positiva, y así es como lo entiende el clasificador.\n",
    "\n",
    "**Texto**: k 19 stays afloat as decent drama/action flick  \n",
    "**Prediccion -1**: 0,66  \n",
    "**Predicción +1**: 0,34\n",
    "\n",
    "La opinión es más bien mixta, y así lo determina el clasificador.\n",
    "\n",
    "**Texto**: in the end , white oleander isn’t an adaptation of a novel . it’s a flashy , star-splashed reduction.  \n",
    "**Predicción -1**: 0,12  \n",
    "**Predicción +1**: 0,88\n",
    "\n",
    "La opinión es negativa, pero el clasificador la considera más cercana a una opinión positiva.\n",
    "\n",
    "**Texto**: if we’re to slap protagonist genevieve leplouff because she’s french , do we have that same option to slap her creators because they’re clueless and inept ?  \n",
    "**Predicción -1**: 0,52  \n",
    "**Predicción +1**: 0,48\n",
    "\n",
    "Es una opinión que no expone claramente su polaridad, por lo que es adecuado que la clasificacion sea mixta.\n",
    "\n",
    "**Texto**: a sentimental mess that never rings true  \n",
    "**Predicción -1**: 0,93  \n",
    "**Predicción +1**: 0,07\n",
    "\n",
    "La opinión es negativa, y así lo entiende el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4 SVM Lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
