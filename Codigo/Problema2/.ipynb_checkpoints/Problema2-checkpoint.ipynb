{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Análisis de Opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Importaciones necesarias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el desarrollo del problema, se importan librerías y módulos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Descripción de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dispone de dos dataframes, uno de entrenamiento y otro de prueba. Cada uno de ellos posee 3554 registros. A su vez, cada registro es descrito por dos características: *sentimiento*, cuyo valor puede ser +1 (opinión positiva) ó -1 (opinión negativa) y *texto*, que contiene la opinión del espectador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Se leen archivos de entrada que contiene datos de entrenamiento\n",
    "ftr = open(\"polarity.train\", \"r\")\n",
    "#Se leen archivos de entrada que contiene datos de prueba\n",
    "fts = open(\"polarity.dev\", \"r\")\n",
    "\n",
    "#Se crea dataframe para datos de entrenamiento\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "train_df['Sentiment'] = train_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    "\n",
    "#Se crea dataframe para datos de prueba\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "test_df['Sentiment'] = test_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    " \n",
    "#Cantidad de registros por cada set de datos\n",
    "num_train = train_df.shape[0]\n",
    "num_test = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Preprocesamiento de texto: Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor* para obtener tokens de un texto (con y sin stemming). Notar que la función recibe como parámetros el texto a analizar, junto con la opción (*True*) o no (*False*) de realizar stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor(text, stemming):\n",
    "    #Se utiliza algoritmo de Porter para stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "\n",
    "    if stemming:\n",
    "        #Se realiza lower-casing y stemming\n",
    "        wordtokens = [stemmer.stem(word.lower()) \\\n",
    "                 for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    else:\n",
    "        #Se realiza lower-casing, pero no stemming\n",
    "        wordtokens = [word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "\n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words += \" \" + word\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se listan los resultados obtenidos utilizando la función *word_extractor* sobre las frases de ejemplo entregadas en el enunciado. Primero se trabaja con stemming, haciendo uso del algoritmo de Porter:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eat cake  \n",
    "**I loved eating the cake**: love eat cake  \n",
    "**I do not love eating cake**: love eat cake  \n",
    "**I don’t love eating the cake**: n’t love eat cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simpl , whi n’t done alreadi  \n",
    "**If you’re good at something, never do it for free**: ’re good someth , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se obtienen resultados pobres. Ello se manifiesta principalmente en que para las cuatro primeras expresiones, el resultado final es el mismo, aún cuando algunas de ellas tienen significados opuestos entre sí. Además, muchas de las expresiones generadas contienen tokens que no tiene significado alguno y se reducen tokens que no son verbos, como *something* y *already*.\n",
    "\n",
    "Sin el uso de stemming, los resultados son los siguientes:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: love eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se observa que los verbos no son reducidos a su tronco léxico base, pero ello favorece que no se reduzcan tokens que no corresponde reducir, valga la redundancia. Sin embargo, sigue siendo imposible distinguir entre una frase determinada y su negación. De todas maneras, se aprecia una mayor coherencia en las expresiones resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Preprocesamiento de texto: Lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor2* para obtener tokens de un texto por medio del proceso de lematización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor2(text, sw):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "    #Se realiza lower-casing y lematizacion\n",
    "    wordtokens = [wordlemmatizer.lemmatize(word.lower()) \\\n",
    "             for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    \n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords, en caso de que sw == True\n",
    "    if sw == True:\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words += \" \" + word\n",
    "    else:\n",
    "        for word in wordtokens:\n",
    "            words += \" \" + word\t\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando las mismas expresiones de la secci ́on anterior, se obtienen los siguientes resultados:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: loved eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Los resultados son practicamente idénticos a los obtenidos sin realizar stemming, excepto por la tercera expresión, donde la forma verbal *loved* se mantiene, pero no marca una diferencia significativa.\n",
    "\n",
    "En resumen, se puede ver que, aunque tanto stemming como lematización tienen sus ventajas y desventajas, lematización obtiene mejores resultados, o en su defecto, la no utilización de stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Construcción de vocabulario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a generar una representación vectorial para cada una de las instancias de la variable *texto* presentes tanto en el dataset de entrenamiento como en el de prueba. Para ello, se utiliza la función *word_extractor2*, junto con la opción de filtrar stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se genera representación vectorial de la variable texto para datos de entrenamiento\n",
    "texts_train1 = [word_extractor2(text, True) for text in train_df.Text]\n",
    "#Se genera representación vectorial de la variable texto para datos de prueba\n",
    "texts_test1 = [word_extractor2(text, True) for text in test_df.Text]\n",
    "\n",
    "vectorizer1 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer1.fit(np.asarray(texts_train1))\n",
    "features_train1 = vectorizer1.transform(texts_train1)\n",
    "features_test1 = vectorizer1.transform(texts_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estas representaciones vectoriales, se obtiene el vocabulario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \n",
      "vocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \n",
      "frecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \n",
      "acompañado de su correspondiente frecuencia:\n",
      "\n",
      "film : 583 ocurrencias\n",
      "movie : 503 ocurrencias\n",
      "one : 259 ocurrencias\n",
      "like : 255 ocurrencias\n",
      "ha : 235 ocurrencias\n",
      "make : 186 ocurrencias\n",
      "story : 177 ocurrencias\n",
      "character : 165 ocurrencias\n",
      "good : 154 ocurrencias\n",
      "time : 148 ocurrencias\n"
     ]
    }
   ],
   "source": [
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocabulario = vectorizer1.get_feature_names()\n",
    "dist = list(np.array(features_train1.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "#Se determina la frecuencia de cada token en el vocabulario\n",
    "word_freq = zip(vocabulario, dist)\n",
    "#Se ordenan los tokens por su frecuencia en orden descendente\n",
    "word_freq_ordered = reversed(sorted(word_freq, key=lambda tup: tup[1]))\n",
    "positions = 10\n",
    "\n",
    "#Se imprime top 10 de tokens (esto es, los 10 tokens mas frecuentes en el vocabulario)\n",
    "print ('Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \\nvocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \\nfrecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \\nacompañado de su correspondiente frecuencia:\\n')\n",
    "for tag, count in word_freq_ordered:\n",
    "    if (positions > 0):\n",
    "        print tag,':', count, 'ocurrencias'\n",
    "        positions -= 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Desempeño de clasificadores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ésta sección, se muestra el desempeño de diversos modelos de clasificación aplicados sobre los datos provistos. Para esto, se expondrá un reporte por cada modelo. Dicho reporte indica la precisión, el recall, el valor-F (también conocido como F1-score) y el soporte de cada clase. El reporte es generado por la función *score_model*, que se implementa a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se construye funcion score_model, la cual evalua el desempeno de un determinado clasificador\n",
    "def score_model(model, x, y, xt, yt, text):\n",
    "    acc_train = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1], yt[:-1])\n",
    "    print 'Precisión datos de entrenamiento %s: %f'%(text, acc_train)\n",
    "    print 'Precisión datos de prueba %s: %f'%(text, acc_test)\n",
    "    print 'Análisis detallado de resultados sobre set de prueba:'\n",
    "    print (classification_report(yt, model.predict(xt), target_names = ['clase +1', 'clase -1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1 Clasificador Bayesiano Ingenuo Binario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, se implementa la función *NAIVE_BAYES*, que servirá para el entrenamiento/ajuste de un clasificador Bayesiano Binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion clasificador bayesiano ingenuo binario\n",
    "def NAIVE_BAYES(x, y, xt, yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_model(model, x, y, xt, yt, 'BernoulliNB')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, se estudian los siguientes casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.958638\n",
      "Precisión datos de prueba BernoulliNB: 0.738531\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.73      0.74      1803\n",
      "   clase -1       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 1: filtrando stopwords, con lematizacion\n",
    "model1 = NAIVE_BAYES(features_train1, labels_train, features_test1, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se requiere generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train2 = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test2 = [word_extractor2(text, False) for text in test_df.Text]\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer2.fit(np.asarray(texts_train2))\n",
    "features_train2 = vectorizer2.transform(texts_train2)\n",
    "features_test2 = vectorizer2.transform(texts_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.955262\n",
      "Precisión datos de prueba BernoulliNB: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 2: sin filtrar stopwords, con lematizacion\n",
    "model2 = NAIVE_BAYES(features_train2, labels_train, features_test2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en la sección anterior, es necesario generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train3 = [word_extractor(text, True) for text in train_df.Text]\n",
    "texts_test3 = [word_extractor(text, True) for text in test_df.Text]\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer3.fit(np.asarray(texts_train3))\n",
    "features_train3 = vectorizer3.transform(texts_train3)\n",
    "features_test3 = vectorizer3.transform(texts_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.942881\n",
      "Precisión datos de prueba BernoulliNB: 0.747819\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = NAIVE_BAYES(features_train3, labels_train, features_test3, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se obtiene una mayor precisión sobre el set de entrenamiento al usar lematización, pero la precisión sobre el set de prueba es mayor con stemming. Si se toman en cuenta la precisión y recall por cada clase (en cada caso), puede decirse que los mejores resultados se consiguen al usar lematización y no filtrar stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han tomado cinco textos y se muestra la predicción sobre cada uno. Sólo se considera el caso 1, dado a que es el modelo que obtiene los mejores resultados (NOTA: Dado a que el siguiente código escoge los textos en forma azarosa, los resultados que imprime no coincidirán con los ejemplos analizados más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13894013  0.86105987] a highly spirited , imaginative kid's movie that broaches neo-augustinian theology : is god stuck in heaven because he's afraid of his best-known creation ?\n",
      "\n",
      "[ 0.74848078  0.25151922] a work that lacks both a purpose and a strong pulse .\n",
      "\n",
      "[ 0.76445327  0.23554673] i can analyze this movie in three words : thumbs friggin' down .\n",
      "\n",
      "[ 0.74280467  0.25719533] a small movie with a big impact .\n",
      "\n",
      "[ 0.05116639  0.94883361] a comedy that is warm , inviting , and surprising .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: ’a’ for creativity but comes across more as a sketch for a full-length comedy .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "La opinión es mixta, pero el clasificador la considera más cercana a una opinión negativa.\n",
    "\n",
    "**Texto**: every once in a while , a movie will come along that turns me into that annoying specimen of humanity that i usually dread encountering the most - the fanboy  \n",
    "**Predicción -1**: 0,94  \n",
    "**Predicción +1**: 0,06\n",
    "\n",
    "La opinión es algo ambigua. Sin embargo, el clasificador la considera más bien una opinión negativa.\n",
    "\n",
    "**Texto**: it just goes to show , an intelligent person isn’t necessarily an admirable storyteller .  \n",
    "**Predicción -1**: 0,53  \n",
    "**Predicción +1**: 0,47\n",
    "\n",
    "Se ve que la opinión es negativa, pero el clasificador la considera más cercana a una opinión mixta.\n",
    "\n",
    "**Texto**: the movie is for fans who can’t stop loving anime , and the fanatical excess built into it .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "Es una opinión más bien neutra, pero el clasificador la asocia más como una crítica negativa.\n",
    "\n",
    "**Texto**: there is truth here  \n",
    "**Predicción -1**: 0,44  \n",
    "**Predicción +1**: 0,56\n",
    "\n",
    "Es una opinión cuyo juicio de valor es difícil de determinar, por lo que resulta apropiado que la predicción del clasificador sea mixta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
