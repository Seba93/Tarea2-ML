{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Análisis de Opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Importaciones necesarias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el desarrollo del problema, se importan librerías y módulos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Descripción de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dispone de dos dataframes, uno de entrenamiento y otro de prueba. Cada uno de ellos posee 3554 registros. A su vez, cada registro es descrito por dos características: *sentimiento*, cuyo valor puede ser +1 (opinión positiva) ó -1 (opinión negativa) y *texto*, que contiene la opinión del espectador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Se leen archivos de entrada que contiene datos de entrenamiento\n",
    "ftr = open(\"polarity.train\", \"r\")\n",
    "#Se leen archivos de entrada que contiene datos de prueba\n",
    "fts = open(\"polarity.dev\", \"r\")\n",
    "\n",
    "#Se crea dataframe para datos de entrenamiento\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "train_df['Sentiment'] = train_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    "\n",
    "#Se crea dataframe para datos de prueba\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment', 'Text'])\n",
    "test_df['Sentiment'] = test_df['Sentiment'].convert_objects(convert_numeric=True)\n",
    " \n",
    "#Cantidad de registros por cada set de datos\n",
    "num_train = train_df.shape[0]\n",
    "num_test = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Preprocesamiento de texto: Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor* para obtener tokens de un texto (con y sin stemming). Notar que la función recibe como parámetros el texto a analizar, junto con la opción (*True*) o no (*False*) de realizar stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor(text, stemming):\n",
    "    #Se utiliza algoritmo de Porter para stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "\n",
    "    if stemming:\n",
    "        #Se realiza lower-casing y stemming\n",
    "        wordtokens = [stemmer.stem(word.lower()) \\\n",
    "                 for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    else:\n",
    "        #Se realiza lower-casing, pero no stemming\n",
    "        wordtokens = [word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "\n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words += \" \" + word\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se listan los resultados obtenidos utilizando la función *word_extractor* sobre las frases de ejemplo entregadas en el enunciado. Primero se trabaja con stemming, haciendo uso del algoritmo de Porter:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eat cake  \n",
    "**I loved eating the cake**: love eat cake  \n",
    "**I do not love eating cake**: love eat cake  \n",
    "**I don’t love eating the cake**: n’t love eat cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simpl , whi n’t done alreadi  \n",
    "**If you’re good at something, never do it for free**: ’re good someth , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se obtienen resultados pobres. Ello se manifiesta principalmente en que para las cuatro primeras expresiones, el resultado final es el mismo, aún cuando algunas de ellas tienen significados opuestos entre sí. Además, muchas de las expresiones generadas contienen tokens que no tiene significado alguno y se reducen tokens que no son verbos, como *something* y *already*.\n",
    "\n",
    "Sin el uso de stemming, los resultados son los siguientes:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: love eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Se observa que los verbos no son reducidos a su tronco léxico base, pero ello favorece que no se reduzcan tokens que no corresponde reducir, valga la redundancia. Sin embargo, sigue siendo imposible distinguir entre una frase determinada y su negación. De todas maneras, se aprecia una mayor coherencia en las expresiones resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Preprocesamiento de texto: Lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se crea la función *word_extractor2* para obtener tokens de un texto por medio del proceso de lematización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor2(text, sw):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    #Se obtienen stopwords del idioma ingles\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1', text)\n",
    "    words = \"\"\n",
    "    #Se realiza lower-casing y lematizacion\n",
    "    wordtokens = [wordlemmatizer.lemmatize(word.lower()) \\\n",
    "             for word in word_tokenize(text.decode('utf-8', 'ignore'))]\n",
    "    \n",
    "    #Se eliminan tokens pertenecientes al conjunto de stopwords, en caso de que sw == True\n",
    "    if sw == True:\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words += \" \" + word\n",
    "    else:\n",
    "        for word in wordtokens:\n",
    "            words += \" \" + word\t\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando las mismas expresiones de la secci ́on anterior, se obtienen los siguientes resultados:\n",
    "\n",
    "**I love to eat cake**: love eat cake  \n",
    "**I love eating cake**: love eating cake  \n",
    "**I loved eating the cake**: loved eating cake  \n",
    "**I do not love eating cake**: love eating cake  \n",
    "**I don’t love eating the cake**: n’t love eating cake  \n",
    "**If it’s so simple, why haven’t you done it already?**: ’s simple , n’t done already  \n",
    "**If you’re good at something, never do it for free**: ’re good something , never free  \n",
    "**Well today I found out what Batman can’t do**: well today found batman ca n’t  \n",
    "\n",
    "Los resultados son practicamente idénticos a los obtenidos sin realizar stemming, excepto por la tercera expresión, donde la forma verbal *loved* se mantiene, pero no marca una diferencia significativa.\n",
    "\n",
    "En resumen, se puede ver que, aunque tanto stemming como lematización tienen sus ventajas y desventajas, lematización obtiene mejores resultados, o en su defecto, la no utilización de stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Construcción de vocabulario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a generar una representación vectorial para cada una de las instancias de la variable *texto* presentes tanto en el dataset de entrenamiento como en el de prueba. Para ello, se utiliza la función *word_extractor2*, junto con la opción de filtrar stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se genera representación vectorial de la variable texto para datos de entrenamiento\n",
    "texts_train1 = [word_extractor2(text, True) for text in train_df.Text]\n",
    "#Se genera representación vectorial de la variable texto para datos de prueba\n",
    "texts_test1 = [word_extractor2(text, True) for text in test_df.Text]\n",
    "\n",
    "vectorizer1 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer1.fit(np.asarray(texts_train1))\n",
    "features_train1 = vectorizer1.transform(texts_train1)\n",
    "features_test1 = vectorizer1.transform(texts_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estas representaciones vectoriales, se obtiene el vocabulario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \n",
      "vocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \n",
      "frecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \n",
      "acompañado de su correspondiente frecuencia:\n",
      "\n",
      "film : 583 ocurrencias\n",
      "movie : 503 ocurrencias\n",
      "one : 259 ocurrencias\n",
      "like : 255 ocurrencias\n",
      "ha : 235 ocurrencias\n",
      "make : 186 ocurrencias\n",
      "story : 177 ocurrencias\n",
      "character : 165 ocurrencias\n",
      "good : 154 ocurrencias\n",
      "time : 148 ocurrencias\n"
     ]
    }
   ],
   "source": [
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocabulario = vectorizer1.get_feature_names()\n",
    "dist = list(np.array(features_train1.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "#Se determina la frecuencia de cada token en el vocabulario\n",
    "word_freq = zip(vocabulario, dist)\n",
    "#Se ordenan los tokens por su frecuencia en orden descendente\n",
    "word_freq_ordered = reversed(sorted(word_freq, key=lambda tup: tup[1]))\n",
    "positions = 10\n",
    "\n",
    "#Se imprime top 10 de tokens (esto es, los 10 tokens mas frecuentes en el vocabulario)\n",
    "print ('Luego, considerando tanto los datos de entrenamiento como los de prueba, es posible formar un \\nvocabulario compuesto de 9811 tokens. A partir de este, se crea un top ten, de acuerdo a la \\nfrecuencia de cada uno A continuación, se muestra cada token perteneciente a este ranking, \\nacompañado de su correspondiente frecuencia:\\n')\n",
    "for tag, count in word_freq_ordered:\n",
    "    if (positions > 0):\n",
    "        print tag,':', count, 'ocurrencias'\n",
    "        positions -= 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Desempeño de clasificadores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ésta sección, se muestra el desempeño de diversos modelos de clasificación aplicados sobre los datos provistos. Para esto, se expondrá un reporte por cada modelo. Dicho reporte indica la precisión, el recall, el valor-F (también conocido como F1-score) y el soporte de cada clase. El reporte es generado por la función *score_model*, que se implementa a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se construye funcion score_model, la cual evalua el desempeno de un determinado clasificador\n",
    "def score_model(model, x, y, xt, yt, text):\n",
    "    acc_train = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1], yt[:-1])\n",
    "    print 'Precisión datos de entrenamiento %s: %f'%(text, acc_train)\n",
    "    print 'Precisión datos de prueba %s: %f'%(text, acc_test)\n",
    "    print 'Análisis detallado de resultados sobre set de prueba:'\n",
    "    print (classification_report(yt, model.predict(xt), target_names = ['clase +1', 'clase -1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1 Clasificador Bayesiano Ingenuo Binario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, se implementa la función *NAIVE_BAYES*, que servirá para el entrenamiento/ajuste de un clasificador Bayesiano Binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion clasificador bayesiano ingenuo binario\n",
    "def NAIVE_BAYES(x, y, xt, yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_model(model, x, y, xt, yt, 'BernoulliNB')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, se emplea dicha función para construir un clasificador aplicado a los siguientes casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.958638\n",
      "Precisión datos de prueba BernoulliNB: 0.738531\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.73      0.74      1803\n",
      "   clase -1       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 1: filtrando stopwords, con lematizacion\n",
    "model1 = NAIVE_BAYES(features_train1, labels_train, features_test1, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se requiere generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train2 = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test2 = [word_extractor2(text, False) for text in test_df.Text]\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer2.fit(np.asarray(texts_train2))\n",
    "features_train2 = vectorizer2.transform(texts_train2)\n",
    "features_test2 = vectorizer2.transform(texts_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.955262\n",
      "Precisión datos de prueba BernoulliNB: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 2: sin filtrar stopwords, con lematizacion\n",
    "model2 = NAIVE_BAYES(features_train2, labels_train, features_test2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que al usar lematización, se obtiene una mayor precisión sobre el set de entrenamiento si se filtran stopwords, pero la precisión es mayor sobre el set de prueba en el caso en que no se filtran. De todas maneras, las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en la sección anterior, es necesario generar una nueva representación vectorial de la variable *texto*, dadas las características especiales del caso estudiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train3 = [word_extractor(text, True) for text in train_df.Text]\n",
    "texts_test3 = [word_extractor(text, True) for text in test_df.Text]\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer3.fit(np.asarray(texts_train3))\n",
    "features_train3 = vectorizer3.transform(texts_train3)\n",
    "features_test3 = vectorizer3.transform(texts_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se está en condiciones de construir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento BernoulliNB: 0.942881\n",
      "Precisión datos de prueba BernoulliNB: 0.747819\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = NAIVE_BAYES(features_train3, labels_train, features_test3, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se obtiene una mayor precisión sobre el set de entrenamiento al usar lematización, pero la precisión sobre el set de prueba es mayor con stemming, aunque sólo al comparar con el caso en que se filtran stopwords. Si se toman en cuenta la precisión y recall por cada clase (en cada caso), puede decirse que los mejores resultados se consiguen al usar lematización y no filtrar stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.1.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han tomado cinco textos y se muestra la predicción sobre cada uno. Sólo se considera el caso 1, dado a que es el modelo que obtiene los mejores resultados (NOTA: Dado a que el siguiente código escoge los textos en forma azarosa, los resultados que imprime no coincidirán con los ejemplos analizados más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99761694  0.00238306] don't hate el crimen del padre amaro because it's anti-catholic . hate it because it's lousy .\n",
      "\n",
      "[ 0.76541125  0.23458875] a singularly off-putting romantic comedy .\n",
      "\n",
      "[ 0.99549141  0.00450859] this ill-fitting tuxedo is strictly off-the-rack .\n",
      "\n",
      "[ 0.93289577  0.06710423] there's just something about watching a squad of psychopathic underdogs whale the tar out of unsuspecting lawmen that reaches across time and distance .\n",
      "\n",
      "[ 0.08678963  0.91321037] none of birthday girl's calculated events take us by surprise . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: ’a’ for creativity but comes across more as a sketch for a full-length comedy .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "La opinión es mixta, pero el clasificador la considera más cercana a una opinión negativa.\n",
    "\n",
    "**Texto**: every once in a while , a movie will come along that turns me into that annoying specimen of humanity that i usually dread encountering the most - the fanboy  \n",
    "**Predicción -1**: 0,94  \n",
    "**Predicción +1**: 0,06\n",
    "\n",
    "La opinión es algo ambigua. Sin embargo, el clasificador la considera más bien una opinión negativa.\n",
    "\n",
    "**Texto**: it just goes to show , an intelligent person isn’t necessarily an admirable storyteller .  \n",
    "**Predicción -1**: 0,53  \n",
    "**Predicción +1**: 0,47\n",
    "\n",
    "Se ve que la opinión es negativa, pero el clasificador la considera más cercana a una opinión mixta.\n",
    "\n",
    "**Texto**: the movie is for fans who can’t stop loving anime , and the fanatical excess built into it .  \n",
    "**Predicción -1**: 0,96  \n",
    "**Predicción +1**: 0,04\n",
    "\n",
    "Es una opinión más bien neutra, pero el clasificador la asocia más como una crítica negativa.\n",
    "\n",
    "**Texto**: there is truth here  \n",
    "**Predicción -1**: 0,44  \n",
    "**Predicción +1**: 0,56\n",
    "\n",
    "Es una opinión cuyo juicio de valor es difícil de determinar, por lo que resulta apropiado que la predicción del clasificador sea mixta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.5.2 Clasificador Bayesiano Ingenuo Multinomial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la función *MULTINOMIAL*, que se utilizará para el entrenamiento/ajuste de un clasificador Bayesiano Ingenuo Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion clasificador bayesiano ingenuo multinomial\n",
    "def MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x,y)\n",
    "    score_model(model, x, y, xt, yt, \"MULTINOMIAL\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de ésta función, se estudian los mismos casos de la sección anterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.959764\n",
      "Precisión datos de prueba MULTINOMIAL: 0.739375\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.73      0.74      1803\n",
      "   clase -1       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 1: filtrando stopwords, con lematizacion\n",
    "model1 = MULTINOMIAL(features_train1, labels_train, features_test1, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.955824\n",
      "Precisión datos de prueba MULTINOMIAL: 0.752322\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.75      0.75      1803\n",
      "   clase -1       0.75      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 2: sin filtrar stopwords, con lematizacion\n",
    "model2 = MULTINOMIAL(features_train2, labels_train, features_test2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, al usar lematización, se obtiene una mayor precisión sobre el set de entrenamiento si se filtran stopwords, pero la precisión es mayor sobre el set de prueba en el caso en que no se filtran. De todas maneras, las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión datos de entrenamiento MULTINOMIAL: 0.942600\n",
      "Precisión datos de prueba MULTINOMIAL: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.75      0.75      0.75      1803\n",
      "   clase -1       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = MULTINOMIAL(features_train3, labels_train, features_test3, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se obtiene una mayor precisión sobre el set de entrenamiento al usar lematización, pero la precisión sobre el set de prueba es mayor con stemming, aunque sólo en comparación con el caso en que se filtran stopwords. Si se toman en cuenta la precisión y recall por cada clase (en cada caso), puede decirse que los mejores resultados se consiguen al usar lematización y no filtrar stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.2.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la misma lógica que en la sección 2.5.1.4. Se considera sólo el primer caso, para el que se obtienen los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00215043  0.99784957] few of the increasingly far-fetched events that first-time writer-director neil burger follows up with are terribly convincing , which is a pity , considering barry's terrific performance .\n",
      "\n",
      "[ 0.17551963  0.82448037] the result is mesmerizing -- filled with menace and squalor .\n",
      "\n",
      "[ 0.81746334  0.18253666] divertingly ridiculous , headbangingly noisy .\n",
      "\n",
      "[ 0.18669125  0.81330875] confessions isn't always coherent , but it's sharply comic and surprisingly touching , so hold the gong .\n",
      "\n",
      "[ 0.70544555  0.29455445] witless , pointless , tasteless and idiotic .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se analizan los siguientes ejemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: passionate , irrational , long-suffering but cruel as a tarantula , helga figures prominently in this movie , and helps keep the proceedings as funny for grown-ups as for rugrats  \n",
    "**Predicción -1**: 0,04  \n",
    "**Predicción +1**: 0,96\n",
    "\n",
    "La opinión es positiva, y así es como le predice el clasificador.\n",
    "\n",
    "**Texto**: an eccentric little comic/thriller deeply in love with its own quirky personality .  \n",
    "**Predicción -1**: 0,23  \n",
    "**Predicción +1**: 0,77\n",
    "\n",
    "La opinión puede considerarse como negativa, pero el clasificador la considera más cercana a una\n",
    "opinión positiva.\n",
    "\n",
    "**Texto**: rice never clearly defines his characters or gives us a reason to care about them .  \n",
    "**Predicción -1**: 0,94  \n",
    "**Predicción +1**: 0,06\n",
    "\n",
    "La opinión es negativa, y así es como el clasificador lo predice.\n",
    "\n",
    "**Texto**: after a while , the only way for a reasonably intelligent person to get through the country bears is to ponder how a whole segment of pop-music history has been allowed to get wet , fuzzy and sticky .  \n",
    "**Predicción -1**: 0,98  \n",
    "**Predicción +1**: 0,02\n",
    "\n",
    "La opinión es negativa, y así es como lo predice el clasificador.\n",
    "\n",
    "**Texto**: The music and the stars aren’t enough to save the movie .  \n",
    "**Predicción -1**: 0,97  \n",
    "**Predicción +1**: 0,03\n",
    "\n",
    "La opinión es negativa, y así es como el clasificador lo entiende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3 Modelo de regresión logística regularizado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la función *LOGIT*, con el propósito de entrenar/ajustar modelos de Regresión Logística Regularizados mediante la norma *l2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion modelo de regresion logistica regularizado\n",
    "def LOGIT(x,y,xt,yt, bestvalue):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01, 0.1, 10, 100, 1000]\n",
    "    if bestvalue == 0:\n",
    "        for C in Cs:\n",
    "            print \"Usando C= %f\"%C\n",
    "            model = LogisticRegression(penalty='l2', C=C)\n",
    "            model= model.fit(x,y)\n",
    "            score_model(model, x, y, xt, yt, \"LOGISTIC\")\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=bestvalue)\n",
    "        model = model.fit(x,y)\n",
    "        score_model(model,x,y,xt,yt, \"LOGISTIC\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que el efecto esperado del parámetro C es regularizar el modelo, es decir, encontrar valores para los coeficientes asociados a cada variable presente en la regresión, de tal manera que se minimice el error de predicción. Así, se estudian los mismos tres casos de siempre, buscando también verificar, en cada uno de ellos, cual es el parámetro C más adecuado para regularizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.787563\n",
      "Precisión datos de prueba LOGISTIC: 0.679144\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.67      0.72      0.69      1803\n",
      "   clase -1       0.69      0.64      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.891390\n",
      "Precisión datos de prueba LOGISTIC: 0.718829\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.72      0.72      0.72      1803\n",
      "   clase -1       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.719674\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.714044\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.70      0.71      1803\n",
      "   clase -1       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.715170\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOGIT(features_train1, labels_train, features_test1, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las métricas que se exponen previamente, se elige el parámetro C = 10 como el más apropiado para realizar la regresión, dado que presenta un buen equilibrio entre precisión sobre el set de entrenamiento y precisión sobre el set de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.721159\n",
      "Precisión datos de prueba LOGISTIC: 0.672390\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.67      0.69      0.68      1803\n",
      "   clase -1       0.67      0.66      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.884074\n",
      "Precisión datos de prueba LOGISTIC: 0.717140\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.72      0.71      0.72      1803\n",
      "   clase -1       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.725865\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.70      0.72      1803\n",
      "   clase -1       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.721925\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.69      0.72      1803\n",
      "   clase -1       0.70      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.720518\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.69      0.72      1803\n",
      "   clase -1       0.70      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = LOGIT(features_train2, labels_train, features_test2, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo las mismas razones de la sección anterior, se aprecia que nuevamente es apropiado eligir C = 10 como parámetro de regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.781373\n",
      "Precisión datos de prueba LOGISTIC: 0.691528\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.69      0.72      0.70      1803\n",
      "   clase -1       0.70      0.66      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.882386\n",
      "Precisión datos de prueba LOGISTIC: 0.728961\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.74      0.73      1803\n",
      "   clase -1       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 0.999719\n",
      "Precisión datos de prueba LOGISTIC: 0.724740\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.72      0.73      1803\n",
      "   clase -1       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.717703\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.71      0.72      1803\n",
      "   clase -1       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.712637\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.70      0.71      1803\n",
      "   clase -1       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = LOGIT(features_train3, labels_train, features_test3, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los mismos motivos expuestos en las dos secciones previas, es conveniente regularizar con C = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar en forma conjunta los tres casos involucrados, se observa que la precisión sobre el set de entrenamiento es la misma, independiente de que se filtren o no stopwords. Sin embargo, la precisión sobre el set de prueba es mayor en el segundo caso. Además, la precisión sobre ambos sets de datos es siempre superior al usar lematización, respecto a usar stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.3.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se toman cinco textos aleatoreamente y se muestra la predicción sobre cada uno. Nuevamente, se considera el caso 1, junto con C = 10, pues es la combinación que entrega los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99404007  0.00595993] whatever complaints i might have , i'd take [its] earnest errors and hard-won rewards over the bombastic self-glorification of other feel-good fiascos like antwone fisher or the emperor's club any time .\n",
      "\n",
      "[ 0.71255131  0.28744869] it appears to have been made by people to whom the idea of narrative logic or cohesion is an entirely foreign concept .\n",
      "\n",
      "[ 0.00132735  0.99867265] a warm but realistic meditation on friendship , family and affection .\n",
      "\n",
      "[ 0.07886371  0.92113629] full frontal , which opens today nationwide , could almost be classified as a movie-industry satire , but it lacks the generous inclusiveness that is the genre's definitive , if disingenuous , feature .\n",
      "\n",
      "[ 0.17747549  0.82252451] maggie smith as the ya-ya member with the o2-tank will absolutely crack you up with her crass , then gasp for gas , verbal deportment .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred1 = model1.predict_proba(features_test1)\n",
    "spl1 = random.sample(xrange(len(test_pred1)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl1], test_pred1[spl1]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: entertains by providing good , lively company .  \n",
    "**Predicción -1**: 0,01  \n",
    "**Predicción +1**: 0,99\n",
    "\n",
    "La opinión es positiva, y así es como lo entiende el clasificador.\n",
    "\n",
    "**Texto**: k 19 stays afloat as decent drama/action flick  \n",
    "**Prediccion -1**: 0,66  \n",
    "**Predicción +1**: 0,34\n",
    "\n",
    "La opinión es más bien mixta, y así lo determina el clasificador.\n",
    "\n",
    "**Texto**: in the end , white oleander isn’t an adaptation of a novel . it’s a flashy , star-splashed reduction.  \n",
    "**Predicción -1**: 0,12  \n",
    "**Predicción +1**: 0,88\n",
    "\n",
    "La opinión es negativa, pero el clasificador la considera más cercana a una opinión positiva.\n",
    "\n",
    "**Texto**: if we’re to slap protagonist genevieve leplouff because she’s french , do we have that same option to slap her creators because they’re clueless and inept ?  \n",
    "**Predicción -1**: 0,52  \n",
    "**Predicción +1**: 0,48\n",
    "\n",
    "Es una opinión que no expone claramente su polaridad, por lo que es adecuado que la clasificacion sea mixta.\n",
    "\n",
    "**Texto**: a sentimental mess that never rings true  \n",
    "**Predicción -1**: 0,93  \n",
    "**Predicción +1**: 0,07\n",
    "\n",
    "La opinión es negativa, y así lo entiende el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4 SVM Lineal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se implementa la función *SVM* para el entrenamiento de Máquinas de Vectores de Soporte Lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementacion de modelo SVM lineal\n",
    "def SVM(x,y,xt,yt, bestvalue):\n",
    "    Cs = [0.01, 0.1, 10, 100, 1000]\n",
    "    if bestvalue == 0: #Cuando el valor de C aun no ha sido escogido, se prueban todos los C\n",
    "        for C in Cs:\n",
    "            print \"El valor de C que se esta probando: %f\"%C\n",
    "            model = SVC(C=C, kernel='linear', probability=True)\n",
    "            model = model.fit(x,y)\n",
    "            score_model(model, x, y, xt, yt, \"SVM\")\n",
    "    else: #Se entrena/ajusta modelo con el valor de C escogido\n",
    "        model = SVC(C=bestvalue, kernel='linear', probability=True)\n",
    "        model = model.fit(x,y)\n",
    "        score_model(model, x, y, xt, yt, \"SVM\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante destacar que el efecto esperado del parametro C es regularizar el modelo, es decir, evitar que este se sobreajuste. En las siguientes secciones, se estudian los tres casos habituales, buscando además determinar el valor de C que permite obtener los mejores resultados en términos de las métricas evaluadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4.1 Caso 1: Filtrando stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Precisión datos de entrenamiento SVM: 0.743950\n",
      "Precisión datos de prueba SVM: 0.655784\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.63      0.79      0.70      1803\n",
      "   clase -1       0.70      0.52      0.60      1751\n",
      "\n",
      "avg / total       0.67      0.66      0.65      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Precisión datos de entrenamiento SVM: 0.937535\n",
      "Precisión datos de prueba SVM: 0.721644\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.72      0.72      1803\n",
      "   clase -1       0.72      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.698565\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.69      0.70      1803\n",
      "   clase -1       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.698565\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.69      0.70      1803\n",
      "   clase -1       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.698565\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.69      0.70      1803\n",
      "   clase -1       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM(features_train1, labels_train, features_test1, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados mostrados, se considera que el parámetro C = 0,1 es el más apropiado,\n",
    "dado que presenta un buen equilibrio entre precisión sobre el set de entrenamiento y precisión sobre el set de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4.2 Caso 2: Sin filtrar stopwords y usando lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Precisión datos de entrenamiento SVM: 0.735228\n",
      "Precisión datos de prueba SVM: 0.674641\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.66      0.73      0.70      1803\n",
      "   clase -1       0.69      0.62      0.65      1751\n",
      "\n",
      "avg / total       0.68      0.67      0.67      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Precisión datos de entrenamiento SVM: 0.932752\n",
      "Precisión datos de prueba SVM: 0.728680\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.72      0.73      1803\n",
      "   clase -1       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.706727\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.68      0.70      1803\n",
      "   clase -1       0.69      0.74      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.706727\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.68      0.70      1803\n",
      "   clase -1       0.69      0.74      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.706727\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.73      0.68      0.70      1803\n",
      "   clase -1       0.69      0.74      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = SVM(features_train2, labels_train, features_test2, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en la sección anterior, las métricas consideradas alcanzan su mejor rendimiento para C = 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4.3 Caso 3: Filtrando stopwords y usando stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Precisión datos de entrenamiento SVM: 0.765616\n",
      "Precisión datos de prueba SVM: 0.674923\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.65      0.76      0.70      1803\n",
      "   clase -1       0.70      0.59      0.64      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.67      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Precisión datos de entrenamiento SVM: 0.923748\n",
      "Precisión datos de prueba SVM: 0.735435\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.74      0.74      1803\n",
      "   clase -1       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.698283\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.68      0.70      1803\n",
      "   clase -1       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.696313\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.68      0.70      1803\n",
      "   clase -1       0.68      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Precisión datos de entrenamiento SVM: 1.000000\n",
      "Precisión datos de prueba SVM: 0.696313\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.71      0.68      0.70      1803\n",
      "   clase -1       0.68      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#caso 3: Filtrando stopwords, con stemming\n",
    "model3 = SVM(features_train3, labels_train, features_test3, labels_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como sucedió en las dos secciones previas, los mejores resultados en base a la precisión alcanzada en cada set de datos se consigue para C = 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, la precisión sobre el set de entrenamiento es prácticamente la misma, tanto para cuando se filtran como cuando no se filtran stopwords, mas la precisión sobre el set de prueba es mayor cuando no se filtran stopwords. Sin embargo, a diferencia de los modelos usados anteriormente, en este caso se obtiene una mayor precisión sobre los datos de prueba al usar stemming respecto a lematización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5.4.4 Análisis de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, se toman cinco textos aleatoreamente y se muestra la predicción sobre cada uno. Se considera el caso 3, junto con C = 0.1, al ser la combinación que entrega los mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Texto**: what a bewilderingly brilliant and entertaining movie this is .  \n",
    "**Predicción -1**: 0,14  \n",
    "**Predicción +1**: 0,86\n",
    "\n",
    "La opinión es positiva y el clasificador efectivamente lo considera así.\n",
    "\n",
    "**Texto**: whether kiss is a future cult classic or destined to be completely forgotten is open to question , but the risk-takers in the crowd should check it out and form their own opinion .  \n",
    "**Predicción -1**: 0,37  \n",
    "**Predicción +1**: 0,63\n",
    "\n",
    "Se puede considerar como un opinión neutra, y en parte asó lo considera el clasificador, aunque más cercana a una opinión positiva.\n",
    "\n",
    "**Texto**: life on the rez is no picnic : this picture shows you why .  \n",
    "**Predicción -1**: 0,47  \n",
    "**Predicción +1**: 0,53\n",
    "\n",
    "Se puede considerar como una opinión neutral. El clasificador también lo considera así.\n",
    "\n",
    "**Texto**: this movie is maddening . it conveys a simple message in a visual style that is willfully over-wrought .  \n",
    "**Predicción -1**: 0,47\n",
    "**Predicción +1**: 0,53\n",
    "\n",
    "La opinión es más bien neutra, y así lo predice el clasificador.\n",
    "\n",
    "**Texto**: with wit and empathy to spare , waydowntown acknowledges the silent screams of workaday inertia but stops short of indulging its characters’ striving solipsism .  \n",
    "**Predicción -1**: 0,60  \n",
    "**Predicción +1**: 0,40\n",
    "\n",
    "Es una opinión mixta, y el clasificador así lo entiende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Comparación de métodos de clasificación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa cada método en base a la cantidad de clasificaciones True Positive (TP), False Positive (FP), True Negative (TN) y False Negative (FN), donde ’el positivo’ es la clase +1, y ’el negativo’ es la clase -1. Para obtener estos valores, es necesario construir la matriz de confusión de cada método. Notar que, para cada método de clasificación, se considera el caso en que cada uno de éstos obtuvo su mejor rendimiento, es decir, para el clasificador bayesiano ingenuo, el clasificador bayesiano multinomial y el modelo de regresión logística regularizado se toma en cuenta el caso 2 (uso lematización, pero sin filtrar stopwords, C = 10), mientras que para la SVM lineal, se considera el caso 3 (uso de stemming, filtrando stopwords, C = 0.1).\n",
    "\n",
    "El procedimiento empleado puede verse a continuación. Se aprovecha también ésta oportunidad generar un cuadro resumen que muestra las métricas ya estudiadas previamente (precisión, recall, f1-score y soporte) para cada uno de los métodos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACIÓN DE MÉTODOS DE CLASIFICACIÓN, EN BASE A MÉTRICAS\n",
      "\n",
      "Precisión datos de entrenamiento BernoulliNB: 0.955262\n",
      "Precisión datos de prueba BernoulliNB: 0.748663\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.74      0.75      1803\n",
      "   clase -1       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Precisión datos de entrenamiento MULTINOMIAL: 0.955824\n",
      "Precisión datos de prueba MULTINOMIAL: 0.752322\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.76      0.75      0.75      1803\n",
      "   clase -1       0.75      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Precisión datos de entrenamiento LOGISTIC: 1.000000\n",
      "Precisión datos de prueba LOGISTIC: 0.725865\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.70      0.72      1803\n",
      "   clase -1       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Precisión datos de entrenamiento SVM: 0.923748\n",
      "Precisión datos de prueba SVM: 0.735435\n",
      "Análisis detallado de resultados sobre set de prueba:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   clase +1       0.74      0.74      0.74      1803\n",
      "   clase -1       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'COMPARACIÓN DE MÉTODOS DE CLASIFICACIÓN\\n'\n",
    "#Se obtienen predicciones realizadas por cada metodo\n",
    "#Para clasificador bayesiano ingenuo binario (con lematizacion, sin filtrar stopwords)\n",
    "model_nb = NAIVE_BAYES(features_train2, labels_train, features_test2, labels_test)\n",
    "estimation1 =  model_nb.predict(features_test2)\n",
    "#Para clasificador bayesiano ingenuo multinomial (con lematizacion, sin filtrar stopwords)\n",
    "model_mn = MULTINOMIAL(features_train2, labels_train, features_test2, labels_test)\n",
    "estimation2 =  model_mn.predict(features_test2)\n",
    "#Para logistic regression (con lematizacion, sin filtrar stopwords)\n",
    "model_lr = LOGIT(features_train2, labels_train, features_test2, labels_test, 10)\n",
    "estimation3 =  model_lr.predict(features_test2)\n",
    "#Para SVM (con stemming, filtrando stopwords)\n",
    "model_svm = SVM(features_train3, labels_train, features_test3, labels_test, 0.1)\n",
    "estimation4 =  model_svm.predict(features_test3)\n",
    "\n",
    "#Se obtiene matriz de confusion para cada metodo\n",
    "cm_binomial = confusion_matrix(labels_test, estimation1)\n",
    "cm_multinomial = confusion_matrix(labels_test, estimation2)\n",
    "cm_logistic = confusion_matrix(labels_test, estimation3)\n",
    "cm_svm = confusion_matrix(labels_test, estimation4)\n",
    "\n",
    "#Se obtiene valores de TP, FP, FN, TN para cada metodo\n",
    "#Para clasificador bayesiano ingenuo binario\n",
    "TP1 = cm_binomial[0][0]\n",
    "FP1 = cm_binomial[0][1]\n",
    "FN1 = cm_binomial[1][0]\n",
    "TN1 = cm_binomial[1][1]\n",
    "\n",
    "#Para clasificador bayesiano ingenuo multinomial\n",
    "TP2 = cm_multinomial[0][0]\n",
    "FP2 = cm_multinomial[0][1]\n",
    "FN2 = cm_multinomial[1][0]\n",
    "TN2 = cm_multinomial[1][1]\n",
    "\n",
    "#Para logistic regression\n",
    "TP3 = cm_logistic[0][0]\n",
    "FP3 = cm_logistic[0][1]\n",
    "FN3 = cm_logistic[1][0]\n",
    "TN3 = cm_logistic[1][1]\n",
    "\n",
    "#Para SVM\n",
    "TP4 = cm_svm[0][0]\n",
    "FP4 = cm_svm[0][1]\n",
    "FN4 = cm_svm[1][0]\n",
    "TN4 = cm_svm[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se procede a construir un gráfico que permite comparar la cantidad de TP, FP, TN y FN de cada método de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construccion de grafico comparativo\n",
    "N = 4\n",
    "TPs = (TP1, TP2, TP3, TP4)\n",
    "FPs = (FP1, FP2, FP3, FP4)\n",
    "FNs = (FN1, FN2, FN3, FN4)\n",
    "TNs = (TN1, TN2, TN3, TN4)\n",
    "\n",
    "ind = np.arange(N)\n",
    "width = 1./(1+N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, TPs, width, color='r')\n",
    "rects2 = ax.bar(ind + width, FPs, width, color='y')\n",
    "rects3 = ax.bar(ind + 2*width, FNs, width, color='b')\n",
    "rects4 = ax.bar(ind + 3*width, TNs, width, color='k')\n",
    "\n",
    "ax.set_ylabel('Metricas')\n",
    "ax.set_title('Metricas por cada metodo de clasificacion')\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(('Bayesiano Ingenuo', 'Multinomial', 'Regresion logistica', 'SVM lineal'))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0], rects3[0], rects4[0]), ('TP', 'FP', 'FN', 'TN'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del gráfico generado, se puede ver que mejor predicción de clase +1 (TP) se logra con un modelo Multinomial, seguido (en orden descendente) por el clasificador binario, el modelo de regresión logística y la SVM lineal. Por otro lado, la clase -1 (TN) obtiene una mejor predicción a partir de un modelo de regresión logística, seguido (en orden descendente) por la SVM lineal, el clasificador binario y el modelo multinomial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
